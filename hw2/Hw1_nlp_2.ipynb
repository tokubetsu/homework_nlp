{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGYWlB4I-f5W"
   },
   "source": [
    "### Выполнила Зыкова Вероника, БКЛ-192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! Из данной версии первого дз удалена часть с клаулером, так как были взяты данные, собранные в предыдущий раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlsZVn74-nM-"
   },
   "source": [
    "##### Импорт всех необходиимых модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kOyTSKII_l6U"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from random import shuffle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vzyko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZWVPPJRn-tbt"
   },
   "outputs": [],
   "source": [
    "name_neg = 'neg_revs.jsonl'\n",
    "name_pos = 'pos_revs.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOC7C_598KTQ"
   },
   "source": [
    "##### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читает файл с данными, где каждыя строка - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    data = data.splitlines()\n",
    "    texts = []\n",
    "    for el in data:\n",
    "        texts.extend(json.loads(el))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация, очистка от пунктуации и прочих не-слов, лемматизация\n",
    "- !NEW получение части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cT8quN3o-YKS"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    conn = {'ADJF': 'ADJ', 'ADJS': 'ADJ', 'COMP': 'ADJ', 'INFN': 'VERB', 'PRTF': 'ADJ', 'PRTS': 'VERB', 'GRND': 'VERB', \n",
    "            'NUMR': 'NUM', 'ADVB': 'ADV', 'NPRO':'PRON', 'PRED': 'ADV', 'PREP': 'ADP', 'PRCL': 'PART'}\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            token_pr = morph.parse(token.lower())[0] \n",
    "            norm_form = token_pr.normal_form\n",
    "            pos = str(token_pr.tag.POS)\n",
    "            if pos in conn:\n",
    "                pos = conn[pos]\n",
    "            lemmas.append((norm_form, pos))\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяет предыдущую функцию ко всем текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0Zt4YZbx-YQH"
   },
   "outputs": [],
   "source": [
    "def clean_all(reviews):\n",
    "    clean_reviews = {}\n",
    "    for mark in reviews:\n",
    "        clean_reviews[mark] = []\n",
    "        for el in reviews[mark]:\n",
    "            text = clean_text(el)\n",
    "            clean_reviews[mark].extend(text)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяет все тексты на тестовую и обучающую выборки, при этом уравнивая количество, если надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(revs, perc=0.2, same=True):\n",
    "    train = {}\n",
    "    test = {}\n",
    "    if same:\n",
    "        line = min([len(revs[i]) for i in revs])\n",
    "    for el in revs:\n",
    "        if not same:\n",
    "            line = len(revs[el])\n",
    "        shuffle(revs[el])\n",
    "        test[el] = revs[el][0:int(perc * line)]\n",
    "        train[el] = revs[el][int(perc * line):line]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем тексты, очищаем обучающую часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = {}\n",
    "revs['neg'] = read_file(name_neg)\n",
    "revs['pos'] = read_file(name_pos)\n",
    "train_text, test_text = train_test(revs)\n",
    "train = clean_all(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем множества, не включая в них слова с частотой меньше нужной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(revs, freq_line=10):\n",
    "    neg_set_full = set(revs['neg'])\n",
    "    pos_set_full = set(revs['pos'])\n",
    "    neg_freq = Counter(revs['neg'])\n",
    "    pos_freq = Counter(revs['pos'])\n",
    "    neg_set = neg_set_full - pos_set_full\n",
    "    pos_set = pos_set_full - neg_set_full\n",
    "    neg_set_tot = set([el for el in neg_set if neg_freq[el] >= freq_line])\n",
    "    pos_set_tot = set([el for el in pos_set if pos_freq[el] >= freq_line])\n",
    "    return neg_set_tot, pos_set_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- !NEW Сохраняем в отдельное множество биграммы, отвечающие шаблонам: не + ADJ, не + VERB, any + но "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patterns(revs):\n",
    "    res = set()\n",
    "    for i in range(1, len(revs)):\n",
    "        if revs[i - 1][0] == 'не':\n",
    "            if revs[i][1] == 'VERB':\n",
    "                res.add((revs[i - 1][0], revs[i][0]))\n",
    "            elif revs[i][1] == 'ADJ':\n",
    "                res.add((revs[i - 1][0], revs[i][0]))\n",
    "        elif revs[i][0] == 'но':\n",
    "            res.add((revs[i - 1][0], revs[i][0]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(revs):\n",
    "    res = set()\n",
    "    for i in range(1, len(revs)):\n",
    "        res.add((revs[i - 1][0], revs[i][0]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_patterns(revs, mode=get_patterns):\n",
    "    negs = mode(revs['neg'])\n",
    "    poss = mode(revs['pos'])\n",
    "    negs_tot = negs - poss\n",
    "    pos_tot = poss - negs\n",
    "    return negs_tot, pos_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XQIBDI5_VzV"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем количество слов, относящихся к негативному и позитивному классу соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text, neg, pos):\n",
    "    text = clean_text(text)\n",
    "    score = [0, 0]\n",
    "    for el in text:\n",
    "        if el in neg:\n",
    "            score[0] += 1\n",
    "        elif el in pos:\n",
    "            score[1] += 1\n",
    "    return tuple(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- !NEW Аналог предыдущей функции для биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_patt(text, neg, pos):\n",
    "    text = clean_text(text)\n",
    "    score = [0, 0]\n",
    "    for i in range(1, len(text)):\n",
    "        if (text[i - 1], text[i]) in neg:\n",
    "            score[0] += 1\n",
    "        elif (text[i - 1], text[i]) in pos:\n",
    "            score[1] += 1\n",
    "    return tuple(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем тип отзыва на основе результата предыдущей функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(text, neg, pos, mode=get_score):\n",
    "    score = mode(text, neg, pos)\n",
    "    return score[1] > score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим выборку к нужному нам виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(test):\n",
    "    test_all = []\n",
    "    marks = {'neg': 0, 'pos': 1}\n",
    "    for mark in test:\n",
    "        for el in test[mark]:\n",
    "            test_all.append([el, marks[mark]])\n",
    "    return test_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем определение тональности всех отзывов в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, neg, pos, mode=get_score):\n",
    "    score = 0\n",
    "    for el in data: \n",
    "        text_type = get_type(el[0], neg, pos, mode)\n",
    "        if text_type == el[1]:\n",
    "            score += 1\n",
    "    return score / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем множества, граница частотности указана в соотвествии с результатом перебора ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = get_sets(train, freq_line=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_test(test_text)\n",
    "train_new = get_test(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- !NEW результаты для биграмм с шаблоном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_patt, pos_patt = get_all_patterns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(train_new, neg_patt, pos_patt, mode=get_score_patt) # на обучающей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test, neg_patt, pos_patt, mode=get_score_patt) # на тестовой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- !NEW результаты для биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_bi, pos_bi = get_all_patterns(train, mode=get_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(train_new, neg_bi, pos_bi, mode=get_score_patt) # на обучающей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test, neg_bi, pos_bi, mode=get_score_patt) # на тестовой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший из полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(train_new, neg, pos) # на обучающей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test, neg, pos) # на тестовой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: для работы с биграммами и тем более биграммами, построенными по шаблону, недостаточно данных в выборке, поэтому результат по сути оказывается равным тому, что мог бы выдать генератор случайных чисел. А модель со словами переобучается."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hw1_nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
