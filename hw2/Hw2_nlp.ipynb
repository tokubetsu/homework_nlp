{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011c67ac",
   "metadata": {},
   "source": [
    "### Выполнила Зыкова Вероника, БКЛ-192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af53203",
   "metadata": {},
   "source": [
    "Необходимые импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11fb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymorphy2\n",
    "import pymystem3\n",
    "from nltk.tokenize import word_tokenize\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d626e9",
   "metadata": {},
   "source": [
    "Читаем размеченные данные. Была выбрана разметка UD с единственным отличием - убран тег PROPN (так как он не определеяется частью остальных парсеров и не так сильно отличается от обычного NOUN, как SCONJ от CCONJ, например). Эта разметка была выбрана как наиболее лаконичная и при этом удобнаая как для целей морфологического анализа, так и для синтаксиса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4ce599",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.json', 'r', encoding='utf-8') as f:\n",
    "    corpus = json.load(f)\n",
    "corpus = [tuple(el) for el in corpus if el[1] != 'PUNCT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5521e0d",
   "metadata": {},
   "source": [
    "Читаем сырой текст. Данные были взяты из трех источников: \n",
    "1. Отчет лаборатории истории диаспор исторического факультета МГУ (в тексте много аббревиатур и имен, что является сложным для парсеров)\n",
    "2. Описание лемматизация и стемминга с сайта, посвященного программированию (термины и заимствования в качестве сложностей)\n",
    "3. Описание инструментов для каллиграфии (редкие слова и заимствовавния)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21793bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624b71c",
   "metadata": {},
   "source": [
    "Разбор частей речи через pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e3dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymorphy_par(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    res = []\n",
    "    for token in tokens:\n",
    "        token_pr = morph.parse(token.lower())[0] \n",
    "        pos = str(token_pr.tag.POS)\n",
    "        res.append((token, pos))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff0cbb",
   "metadata": {},
   "source": [
    "Приводим разметку к нужной (функция универсальна для всех трех парсеров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98012135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(posses, conn):\n",
    "    new = []\n",
    "    for el in posses:\n",
    "        if el[1] in conn:\n",
    "            new.append((el[0], conn[el[1]]))\n",
    "        else:\n",
    "            new.append(el)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d1902",
   "metadata": {},
   "source": [
    "Сопостравляем токенизацию с той, которая есть в собранных данных (функция универсальна для всех трех парсеров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259d2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(posses, corpus):\n",
    "    res = []\n",
    "    i = 0\n",
    "    cur = ''\n",
    "    for el in corpus:\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            if i >= len(posses):\n",
    "                stop = True\n",
    "            elif posses[i][0] == el[0]:\n",
    "                stop = True\n",
    "                res.append(posses[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                if el[0].startswith(posses[i][0]):\n",
    "                    stop = True\n",
    "                    cur += posses[i][0]\n",
    "                    i += 1\n",
    "                    while cur:\n",
    "                        if el[0].endswith(posses[i][0]):\n",
    "                            cur += posses[i][0]\n",
    "                            res.append((cur, posses[i][1]))\n",
    "                            cur = ''\n",
    "                            i += 1\n",
    "                        else:\n",
    "                            cur += posses[i][0]\n",
    "                            i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaf4b5",
   "metadata": {},
   "source": [
    "Собираем весь разбор pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6313b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pymorphy_par(text)\n",
    "conn = {'ADJF': 'ADJ', 'ADJS': 'ADJ', 'COMP': 'ADJ', 'INFN': 'VERB', 'PRTF': 'ADJ', 'PRTS': 'VERB', 'GRND': 'VERB', \n",
    "            'NUMR': 'NUM', 'ADVB': 'ADV', 'NPRO':'PRON', 'PRED': 'ADV', 'PREP': 'ADP', 'PRCL': 'PART'}\n",
    "pm = rename(pm, conn)\n",
    "pm = connect(pm, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0a9fb",
   "metadata": {},
   "source": [
    "Части речи mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1032ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystem_par(text):\n",
    "    m = pymystem3.Mystem()\n",
    "    an = m.analyze(text)\n",
    "    res = []\n",
    "    for el in an:\n",
    "        s = el['text']\n",
    "        if 'analysis' in el:\n",
    "            pos = el['analysis'][0]['gr']\n",
    "            pos = pos.split('=')[0]\n",
    "            pos = pos.split(',')[0]\n",
    "        else:\n",
    "            pos = None\n",
    "        res.append((s, pos))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb32551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ce14f3",
   "metadata": {},
   "source": [
    "Собираем весь mystem вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f905e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mystem_par(text)\n",
    "conn = {'A': 'ADJ', 'ADVPRO': 'ADV', 'ANUM': 'NUM', 'APRO': 'DET', 'PR': 'ADP', 'V': 'VERB', 'SPRO':'PRON', 'S': 'NOUN'}\n",
    "ms = rename(ms, conn)\n",
    "ms = connect(ms, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e898036",
   "metadata": {},
   "source": [
    "Части речи Наташи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe2cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nata_par(text):\n",
    "    emb = NewsEmbedding()\n",
    "    segmenter = Segmenter()\n",
    "    morph_vocab = MorphVocab()\n",
    "    \n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    \n",
    "    res = []\n",
    "    for el in doc.tokens:\n",
    "        if el.pos != 'PUNCT':\n",
    "            res.append((el.text, el.pos))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f20d9",
   "metadata": {},
   "source": [
    "Собираем Наташу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73e4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = nata_par(text)\n",
    "conn = {'PROPN': 'NOUN'}\n",
    "nt = rename(nt, conn)\n",
    "nt = connect(nt, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6e7f1",
   "metadata": {},
   "source": [
    "Функция оценки результатов работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95dcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(posses, curpus, mist=False):\n",
    "    res = {mod: 0 for mod in posses.keys()}\n",
    "    for i, el in enumerate(corpus):\n",
    "        for mod in posses.keys():\n",
    "            if el[1] == posses[mod][i][1]:\n",
    "                res[mod] += 1\n",
    "            elif ((el[1] == 'SCONJ') or (el[1] == 'CCONJ')) and (posses[mod][i][1] == 'CONJ'):\n",
    "                res[mod] += 1\n",
    "            elif (el[1] == 'AUX') and (posses[mod][i][1] == 'VERB'):\n",
    "                res[mod] += 1\n",
    "            else:\n",
    "                if mist:\n",
    "                    print(f'Mistake: {mod} -- {el} -- {posses[mod][i]}')\n",
    "    for el in res:\n",
    "        res[el] = res[el] / len(corpus)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339d35f",
   "metadata": {},
   "source": [
    "Собираем всю выдачу в один словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e51513",
   "metadata": {},
   "outputs": [],
   "source": [
    "posses = {'natasha': nt, 'mystem': ms, 'pymorphy': pm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc9072",
   "metadata": {},
   "source": [
    "Результаты разборов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fbb0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natasha': 0.8984615384615384,\n",
       " 'mystem': 0.9323076923076923,\n",
       " 'pymorphy': 0.8861538461538462}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res(posses, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bab87",
   "metadata": {},
   "source": [
    "N-граммы для поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69e81e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = ['не VERB', 'VERB NOUN', 'NOUN VERB NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6ed8b",
   "metadata": {},
   "source": [
    "Функция поиска н-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2676c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_grams(text, grams):\n",
    "    res = {gr: [] for gr in grams}\n",
    "    gram = {}\n",
    "    for el in grams:\n",
    "        pat = el.split()\n",
    "        pat_nums = [int(i.isupper()) for i in pat]\n",
    "        pats = [(pat[i], pat_nums[i]) for i in range(len(pat))]\n",
    "        gram[el] = [pats, 0]\n",
    "    \n",
    "    cur = {gr: [] for gr in grams}\n",
    "    for el in text:\n",
    "        for gr in gram:\n",
    "            x = gram[gr][0][gram[gr][1]][1]\n",
    "            w = gram[gr][0][gram[gr][1]][0]\n",
    "            if el[x].lower() == w.lower():\n",
    "                cur[gr].append(el[0])\n",
    "                gram[gr][1] += 1\n",
    "            else:\n",
    "                if len(cur[gr]) > 0:\n",
    "                    cur[gr] = []\n",
    "                    gram[gr][1] = 0\n",
    "            if len(cur[gr]) == len(gram[gr][0]):\n",
    "                res[gr].append(' '.join(cur[gr]))\n",
    "                cur[gr] = []\n",
    "                gram[gr][1] = 0\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abda0d9",
   "metadata": {},
   "source": [
    "Результаты поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553226e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'не VERB': ['не понимает', 'не иметь'],\n",
       " 'VERB NOUN': ['курирует лаборатория',\n",
       "  'состоялась встреча',\n",
       "  'отличаются Стемминг',\n",
       "  'использует словарь',\n",
       "  'привести слово',\n",
       "  'понимает разницу',\n",
       "  'иметь значения',\n",
       "  'соблюдать наклон',\n",
       "  'разработать руку'],\n",
       " 'NOUN VERB NOUN': ['итоге привести слово']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_grams(corpus, grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb2c0e",
   "metadata": {},
   "source": [
    "Остальное см. в тетрадке Hw1_nlp_2 в этой же папке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
