{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGYWlB4I-f5W"
   },
   "source": [
    "### Выполнила Зыкова Вероника, БКЛ-192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlsZVn74-nM-"
   },
   "source": [
    "##### Импорт всех необходиимых модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i7GbK3TJ-Uyg"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.session()\n",
    "import bs4\n",
    "import re\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kOyTSKII_l6U"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vzyko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzdE9Sd7768N"
   },
   "source": [
    "##### Выгрузка с irecommend отзывов, имеющих отценки 1 и 5 (отрицательные и положительные соответственно) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылки, с которых выгружаются данные (их три, потому что у одного больше отрицательнх, у двух других - положительных), и названия файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZWVPPJRn-tbt"
   },
   "outputs": [],
   "source": [
    "URL = ['https://irecommend.ru/content/anex-tour/', 'https://irecommend.ru/content/ics-travel-group/', \\\n",
    "    'https://irecommend.ru/content/turoperator-kareliya-gid/', 'https://irecommend.ru/content/bolshoi-altai-turoperator/']\n",
    "BASEURL = 'https://irecommend.ru'\n",
    "name_neg = 'neg_revs.jsonl'\n",
    "name_pos = 'pos_revs.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вид, что это браузер, а не питоновский скрипт стучится на сайт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b9hJArD3EmId"
   },
   "outputs": [],
   "source": [
    "def get_headers():\n",
    "    ua = UserAgent(verify_ssl=False)\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получает оценку отзыва, чтобы открывать ссылки только с нужными и не нервировать защиту сайта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "byn6tpkMEoKN"
   },
   "outputs": [],
   "source": [
    "def get_mark(li):\n",
    "    data = li.find('div', {'class': 'starsRating'}).find_all('div', {'class': 'star'})\n",
    "    data = [i.find('div').get('class')[0] for i in data].count('on')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получает все нужные ссылки со страницы: ссылки на отзывы + ссылку на следующую страницу, если она есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9cTa4C86A5fR"
   },
   "outputs": [],
   "source": [
    "def get_links(url, marks=(1, 5), headers=None):\n",
    "    links = {mark: [] for mark in marks}\n",
    "    response = session.get(url, headers=headers)\n",
    "    bs_obj = bs4.BeautifulSoup(response.text, features='html.parser')\n",
    "    data = bs_obj.find('ul', {'class': 'list-comments'}).find_all('li')\n",
    "    for li in data:\n",
    "        mark = get_mark(li)\n",
    "        if int(mark) in marks:\n",
    "            link = li.find('div', {'class': 'reviewTitle'}).find('a').get('href')\n",
    "            links[mark].append(link)\n",
    "\n",
    "    next_link = bs_obj.find('li', {'class': 'pager-item'})\n",
    "    if next_link:\n",
    "        next_link = next_link.find('a').get('href')\n",
    "    else:\n",
    "        next_link = bs_obj.find('li', {'class': 'pager-last'})\n",
    "        if next_link:\n",
    "              next_link = next_link.find('a').get('href')\n",
    "        else:\n",
    "              next_link = ''\n",
    "    return links, next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляет из текста все тэги разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xnPkOfPuq2-v"
   },
   "outputs": [],
   "source": [
    "def delete_tags(line):\n",
    "    pattern = re.compile(r'<.+?>')\n",
    "    clean_line = re.sub(pattern, '', line)\n",
    "    pattern = re.compile(r'\\S')\n",
    "    if not re.match(pattern, clean_line):\n",
    "        return ''\n",
    "    else:\n",
    "        return clean_line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получает текст отзыва по ссылке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1zWkhRuLKifZ"
   },
   "outputs": [],
   "source": [
    "def get_review(url, headers, base_url=BASEURL):\n",
    "    url = base_url + url\n",
    "    response = session.get(url, headers=headers)\n",
    "    bs_obj = bs4.BeautifulSoup(response.text, features='html.parser')\n",
    "    summary = delete_tags(str(bs_obj.find('a', {'class': 'review-summary'})))\n",
    "    text_new = bs_obj.find('div', {'class': 'reviewText'}).find_all('p')\n",
    "    text = summary\n",
    "    for el in text_new:\n",
    "        l = delete_tags(str(el))\n",
    "        text += ' ' + l\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собирает все отзывы со страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jL34yGqD_WV9"
   },
   "outputs": [],
   "source": [
    "def get_reviews(url, marks=(1, 5)):\n",
    "    reviews = {}\n",
    "    headers = get_headers()\n",
    "    links, next_link = get_links(url, marks=marks, headers=headers)\n",
    "    print('link done')\n",
    "    time.sleep(randint(10, 15))\n",
    "    for mark in links:\n",
    "        if mark not in reviews:\n",
    "            reviews[mark] = []\n",
    "        for link in links[mark]:\n",
    "            headers = get_headers()\n",
    "            review = get_review(link, headers=headers)\n",
    "            print('rev done')\n",
    "            time.sleep(randint(10, 15))\n",
    "            reviews[mark].append(review)\n",
    "    return reviews, next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняет собранное в json, чтобы иметь подстраховку на случай падения программы и просто не скачивать каждый раз заново"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NldcylWeWgW5"
   },
   "outputs": [],
   "source": [
    "def save_jsonl(f_obj_neg, f_obj_pos, data):\n",
    "    for mark in data:\n",
    "        line = json.dumps(data[mark])\n",
    "        if mark >= 3:\n",
    "            f_obj_pos.write(line + '\\n')\n",
    "        else:\n",
    "            f_obj_neg.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собирает все вышеперечисленное в одну функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "RxZAWHBMvSdZ"
   },
   "outputs": [],
   "source": [
    "def get_all(url, number=200, marks=(1, 5), f_obj_neg=None, f_obj_pos=None):\n",
    "    reviews = {mark: [] for mark in marks}\n",
    "    amount = number // 2 + 1\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        stop = True\n",
    "        new_revs, new_link = get_reviews(url)\n",
    "        if f_obj_neg and f_obj_pos:\n",
    "            save_jsonl(f_obj_neg, f_obj_pos, new_revs)\n",
    "        for mark in marks:\n",
    "            reviews[mark].extend(new_revs[mark])\n",
    "            if len(reviews[mark]) < amount:\n",
    "                stop = False\n",
    "            print(f'{mark}: done {len(reviews[mark])} of {amount}')\n",
    "        if new_link != '':\n",
    "            url = BASEURL + new_link\n",
    "        else:\n",
    "            stop = True\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызывает основную функцию со всеми нужными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "r6VoPWrrX7YN"
   },
   "outputs": [],
   "source": [
    "with open(name_neg, 'a', encoding='utf-8') as f_neg, open(name_pos, 'a', encoding='utf-8') as f_pos:\n",
    "    reviews = get_all(URL[3], number=200, f_obj_neg=f_neg, f_obj_pos=f_pos, marks=(5, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOC7C_598KTQ"
   },
   "source": [
    "##### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читает файл с данными, где каждыя строка - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    data = data.splitlines()\n",
    "    texts = []\n",
    "    for el in data:\n",
    "        texts.extend(json.loads(el))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация, очистка от пунктуации и прочих не-слов, лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cT8quN3o-YKS"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            token_pr = morph.parse(token.lower())[0] \n",
    "            norm_form = token_pr.normal_form\n",
    "            lemmas.append(norm_form)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяет предыдущую функцию ко всем текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Zt4YZbx-YQH"
   },
   "outputs": [],
   "source": [
    "def clean_all(reviews):\n",
    "    clean_reviews = {}\n",
    "    for mark in reviews:\n",
    "        clean_reviews[mark] = []\n",
    "        for el in reviews[mark]:\n",
    "            text = clean_text(el)\n",
    "            clean_reviews[mark].extend(text)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяет все тексты на тестовую и обучающую выборки, при этом уравнивая количество, если надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(revs, perc=0.2, same=True):\n",
    "    train = {}\n",
    "    test = {}\n",
    "    if same:\n",
    "        line = min([len(revs[i]) for i in revs])\n",
    "    for el in revs:\n",
    "        if not same:\n",
    "            line = len(revs[el])\n",
    "        shuffle(revs[el])\n",
    "        test[el] = revs[el][0:int(perc * line)]\n",
    "        train[el] = revs[el][int(perc * line):line]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amount(revs):\n",
    "    res = {mark: len(revs[mark]) for mark in revs}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем тексты, очищаем обучающую часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = {}\n",
    "revs['neg'] = read_file(name_neg)\n",
    "revs['pos'] = read_file(name_pos)\n",
    "train_text, test_text = train_test(revs)\n",
    "train = clean_all(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем множества, не включая в них слова с частотой меньше нужной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(revs, freq_line=10):\n",
    "    neg_set_full = set(revs['neg'])\n",
    "    pos_set_full = set(revs['pos'])\n",
    "    neg_freq = Counter(revs['neg'])\n",
    "    pos_freq = Counter(revs['pos'])\n",
    "    neg_set = neg_set_full - pos_set_full\n",
    "    pos_set = pos_set_full - neg_set_full\n",
    "    neg_set_tot = set([el for el in neg_set if neg_freq[el] >= freq_line])\n",
    "    pos_set_tot = set([el for el in pos_set if pos_freq[el] >= freq_line])\n",
    "    return neg_set_tot, pos_set_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XQIBDI5_VzV"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем количество слов, относящихся к негативному и позитивному классу соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text, neg, pos):\n",
    "    text = clean_text(text)\n",
    "    score = [0, 0]\n",
    "    for el in text:\n",
    "        if el in neg:\n",
    "            score[0] += 1\n",
    "        elif el in pos:\n",
    "            score[1] += 1\n",
    "    return tuple(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем тип отзыва на основе результата предыдущей функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(text, neg, pos):\n",
    "    score = get_score(text, neg, pos)\n",
    "    return score[1] > score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим выборку к нужному нам виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(test):\n",
    "    test_all = []\n",
    "    marks = {'neg': 0, 'pos': 1}\n",
    "    for mark in test:\n",
    "        for el in test[mark]:\n",
    "            test_all.append([el, marks[mark]])\n",
    "    return test_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем определение тональности всех отзывов в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, neg, pos):\n",
    "    score = 0\n",
    "    for el in data: \n",
    "        text_type = get_type(el[0], neg, pos)\n",
    "        if text_type == el[1]:\n",
    "            score += 1\n",
    "    return score / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем множества, граница частотности указана в соотвествии с результатом перебора ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = get_sets(train, freq_line=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_test(test_text)\n",
    "train_new = get_test(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший из полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(train_new, neg, pos) # на обучающей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test, neg, pos) # на тестовой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебираем параметры частотности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FCfoliXT_Zd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.8666666666666667\n",
      "1: 0.8666666666666667\n",
      "2: 0.8333333333333334\n",
      "3: 0.8666666666666667\n",
      "4: 0.8333333333333334\n",
      "5: 0.7333333333333333\n",
      "6: 0.7666666666666667\n",
      "7: 0.7666666666666667\n",
      "8: 0.7\n",
      "9: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    neg, pos = get_sets(train, freq_line=i)\n",
    "    print(f'{i}: {evaluate(test, neg, pos)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9FUDifJ_aGl"
   },
   "source": [
    "##### Улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iMpggBW_cti"
   },
   "source": [
    "1. Можно подсчитывать не просто количество слов из положительного или отрицательного списка, а использовать еще и то, как эти слова распределены по частоте в отзывах. Например, если слово изста положительных отзывов встретилось только в одном, а в отрицательных не встретилось вообще, то достаточно странно считать его маркером положительного отзыва, так как у нас просто слишком мало данных, чтобы что-то такое утверждать. С другой стороны, слово ужасно однозначно встречается во многих отрицательных отзывах и является более достоверным маркером. Чтобы различать такие ситуации, можно при подсчете баллов за положительный или отрицательный ответ прибавлять не единицу, а долю отзывов, содержащих это слово.\n",
    "\n",
    "2. Также можно перейти на вероятностную модель ответа (с помощью описанного выше это будет не так сложно): для каждого отзыва считать не какой он по тональности, а с какой вероятностью он имеет какую-то тональность. Таким образом можно будет задавать границу для определения отношения к классу: если нам вдргу захочется, чтобы все отзывы, отмеченные негативом, точно такими были, то мы можем задать высокий порог вероятности для негативных отзывов."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hw1_nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
